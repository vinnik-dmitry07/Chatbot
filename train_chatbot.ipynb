{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPoEw7D0agQ5IGkwtH7gAWJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinnik-dmitry07/Chatbot/blob/main/train_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAbMlxO9DI4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88684311-6e92-488f-dc0a-91281d5a01ae"
      },
      "source": [
        "!nvidia-smi\r\n",
        "!pip install --quiet parlai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Mar  5 14:46:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 5.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.3MB 55.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 57.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 59.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 60.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 12.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.1MB 56.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 48.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 10.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 52.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 57.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 317kB 44.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 60.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8MB 50.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 56.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 40kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 59.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 56.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 11.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.4MB/s \n",
            "\u001b[?25h  Building wheel for docformatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for websocket-server (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for untokenize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1+cu101 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: omegaconf 2.0.6 has requirement PyYAML>=5.1.*, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: myst-parser 0.12.10 has requirement sphinx<4,>=2, but you'll have sphinx 1.8.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fvcore 0.1.3.post20210305 has requirement pyyaml>=5.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: sphinx-autodoc-typehints 1.11.1 has requirement Sphinx>=3.0, but you'll have sphinx 1.8.5 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY3EisQ766aP"
      },
      "source": [
        "from pathlib import Path\r\n",
        "\r\n",
        "GDRIVE_ROOT = Path('/content/drive/MyDrive/')\r\n",
        "SAVE_DIR = GDRIVE_ROOT / 'chatbot_model'\r\n",
        "DATA_DIR = GDRIVE_ROOT / 'chatbot_data'\r\n",
        "SAVE_EVERY_N_MINUTES = 40  # ~ -1.23 GB from drive every 40 minutes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9y2IWmWDFjU"
      },
      "source": [
        "from datetime import timedelta\r\n",
        "\r\n",
        "EPISODE_DT = timedelta(minutes=3)  # change to split messages in separate dialogues if time delta is greater than EPISODE_DT\r\n",
        "TRAIN_PART, TEST_PART, VALID_PART = 0.996, 0.002, 0.002\r\n",
        "\r\n",
        "assert TRAIN_PART + TEST_PART + VALID_PART == 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr8wrt68ATZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c615b4a5-2857-470e-833b-3f30bc027160"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount(str(GDRIVE_ROOT.parent))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCM-AVZhHKFK"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "with open(DATA_DIR / 'result.json', 'r', encoding='utf8') as f:\r\n",
        "    raw_messages = json.load(f)['messages']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3CvK47rIujd"
      },
      "source": [
        "from datetime import datetime\r\n",
        "\r\n",
        "filtered_messages = []\r\n",
        "for msg in raw_messages:\r\n",
        "    if (\r\n",
        "            'from' in msg and\r\n",
        "            'from_id' in msg and\r\n",
        "            'mime_type' not in msg and\r\n",
        "            msg['text'] and\r\n",
        "            isinstance(msg['text'], str) and\r\n",
        "            len(msg['text']) < 50\r\n",
        "    ):\r\n",
        "        msg1 = msg.copy()\r\n",
        "        msg1['date'] = datetime.strptime(msg1['date'], '%Y-%m-%dT%H:%M:%S')\r\n",
        "        filtered_messages.append(msg1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz06qsAJJLda"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "joined_messages = []\r\n",
        "for i in range(len(filtered_messages)):\r\n",
        "    alphanum_text = re.sub(r'[^A-Za-z0-9 ]+', '', filtered_messages[i]['text']).strip()\r\n",
        "    if alphanum_text:\r\n",
        "        if (    \r\n",
        "                joined_messages and    \r\n",
        "                filtered_messages[i - 1]['from_id'] == filtered_messages[i]['from_id'] and\r\n",
        "                filtered_messages[i - 1]['date'] - filtered_messages[i]['date'] <= EPISODE_DT\r\n",
        "        ):\r\n",
        "            joined_messages[-1]['text'] += ' ' + alphanum_text\r\n",
        "        else:\r\n",
        "            new_message = filtered_messages[i].copy()\r\n",
        "            new_message['text'] = alphanum_text\r\n",
        "            joined_messages.append(new_message)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUphzoX3K_FF"
      },
      "source": [
        "def partition(alist, indices):\r\n",
        "    return [alist[a:b] for a, b in zip([0] + indices, indices + [None])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXMAHZTxL-KN"
      },
      "source": [
        "def save_jsonl(messages, suffix, human_readable=False):\r\n",
        "    time_diffs = [messages[i + 1]['date'] - messages[i]['date'] for i in range(len(messages) - 1)]\r\n",
        "    split_positions = [i + 1 for i in range(len(time_diffs)) if time_diffs[i] > EPISODE_DT]\r\n",
        "    episodes = partition(messages, split_positions)\r\n",
        "    print(f'{suffix} episodes: {len(episodes)}, messages: {len(messages)}')\r\n",
        "\r\n",
        "    with open(DATA_DIR / f'data_{suffix}.jsonl', 'w', **({'encoding': 'utf8'} if human_readable else {})) as outfile:\r\n",
        "        for episode in episodes:\r\n",
        "            dialog = [{'id': i % 2, 'text': msg['text']} for i, msg in enumerate(episode)]\r\n",
        "            episode = {'dialog': [dialog]}\r\n",
        "            json.dump(episode, outfile, **({'ensure_ascii': False} if human_readable else {}))\r\n",
        "            outfile.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApxWsw2omwax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86e7250-7cca-4f85-a428-1c7afcd5e58d"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "train, test, valid = np.split(joined_messages, [\r\n",
        "    int(TRAIN_PART * len(joined_messages)),\r\n",
        "    int((TRAIN_PART + TEST_PART) * len(joined_messages)),\r\n",
        "])\r\n",
        "\r\n",
        "save_jsonl(train, suffix='train')\r\n",
        "save_jsonl(test, suffix='test')\r\n",
        "save_jsonl(valid, suffix='valid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train episodes: 424, messages: 754917\n",
            "test episodes: 1, messages: 1516\n",
            "valid episodes: 1, messages: 1516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HWEdG7hMboN"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "os.environ['SAVE_DIR'] = str(SAVE_DIR)\r\n",
        "!rm --recursive --force $SAVE_DIR\r\n",
        "!mkdir --parents $SAVE_DIR\r\n",
        "\r\n",
        "# v1 training\r\n",
        "from parlai.scripts.train_model import TrainModel\r\n",
        "\r\n",
        "TrainModel.main(\r\n",
        "    task='jsonfile',\r\n",
        "    jsonfile_datapath=str(DATA_DIR / 'data'),\r\n",
        "    jsonfile_datatype_extension=True,\r\n",
        "\r\n",
        "    model='transformer/generator',\r\n",
        "    model_file=str(SAVE_DIR / 'model_v1'),\r\n",
        "    \r\n",
        "    init_model='zoo:tutorial_transformer_generator/model',\r\n",
        "\r\n",
        "    n_heads=16, n_layers=8, n_positions=512, text_truncate=512,\r\n",
        "    label_truncate=128, ffn_size=2048, embedding_size=512,\r\n",
        "    activation='gelu', variant='xlm',\r\n",
        "    dict_lower=True, dict_tokenizer='bpe',\r\n",
        "    dict_file='zoo:tutorial_transformer_generator/model.dict',\r\n",
        "    learn_positional_embeddings=True,\r\n",
        "    \r\n",
        "    lr=1e-5, optimizer='adam',\r\n",
        "    warmup_updates=5000,\r\n",
        "    validation_metric='ppl',\r\n",
        "    validation_every_n_secs=SAVE_EVERY_N_MINUTES * 60,  # running eval: valid\r\n",
        "    # save_every_n_secs=60,  # saving model checkpoint\r\n",
        "\r\n",
        "    batchsize=12, fp16=True, fp16_impl='mem_efficient',\r\n",
        "    \r\n",
        "    skip_generation=True,\r\n",
        "    \r\n",
        "    dynamic_batching='full',\r\n",
        "\r\n",
        "    label_turns='both',  # https://parl.ai/docs/core/teachers.html#parlai.core.teachers.ConversationTeacher\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3nybeRI2ST6",
        "outputId": "282a1fa5-43eb-496d-cd7b-f0471fa15e03"
      },
      "source": [
        "# v2 training\r\n",
        "from parlai.scripts.train_model import TrainModel\r\n",
        "\r\n",
        "TrainModel.main(\r\n",
        "    task='jsonfile',\r\n",
        "    jsonfile_datapath=str(DATA_DIR / 'data'),\r\n",
        "    jsonfile_datatype_extension=True,\r\n",
        "    model_file=str(SAVE_DIR / 'model_v2'),\r\n",
        "    dynamic_batching='full',\r\n",
        "    label_turns='both',\r\n",
        "\r\n",
        "    # task='blended_skill_talk,wizard_of_wikipedia,convai2:normalized',\r\n",
        "    model='transformer/generator',\r\n",
        "    multitask_weights=(1, 3, 3, 3),  #\r\n",
        "    init_model='zoo:tutorial_transformer_generator/model',\r\n",
        "    dict_file='zoo:tutorial_transformer_generator/model.dict',\r\n",
        "    embedding_size=512,\r\n",
        "    n_layers=8,\r\n",
        "    ffn_size=2048,\r\n",
        "    dropout=0.1,  #\r\n",
        "    n_heads=16,\r\n",
        "    learn_positional_embeddings=True,\r\n",
        "    n_positions=512,\r\n",
        "    variant='xlm',\r\n",
        "    activation='gelu',\r\n",
        "    skip_generation=True,\r\n",
        "    fp16=True,\r\n",
        "    text_truncate=512,\r\n",
        "    label_truncate=128,\r\n",
        "    dict_tokenizer='bpe',\r\n",
        "    dict_lower=True,\r\n",
        "    lr=1e-06,\r\n",
        "    optimizer='adamax',  #\r\n",
        "    lr_scheduler='reduceonplateau',  #\r\n",
        "    gradient_clip=0.1,  #\r\n",
        "    validation_every_n_epochs=0.25,  #\r\n",
        "    betas=(0.9, 0.999),  #\r\n",
        "    update_freq=1,  #\r\n",
        "    attention_dropout=0.0,  #\r\n",
        "    relu_dropout=0.0,  #\r\n",
        "    validation_patience=15,  #\r\n",
        "    save_every_n_secs=60,\r\n",
        "    validation_max_exs=20000,  #\r\n",
        "    batchsize=16,\r\n",
        "    validation_metric='ppl',\r\n",
        "    validation_metric_mode='min',  #\r\n",
        "    save_after_valid=True,  #\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15:47:37 | building dictionary first...\n",
            "15:47:37 | No model with opt yet at: /content/drive/MyDrive/chatbot_model/model2(.opt)\n",
            "15:47:37 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: full,verbose: False,datapath: /usr/local/lib/python3.7/dist-packages/data,eval_dynamic_batching: None,load_from_checkpoint: True,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,mutators: None,jsonfile_datapath: /content/drive/MyDrive/chatbot_data/data,jsonfile_datatype_extension: True,label_turns: both,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,beam_block_full_context: True,beam_length_penalty: 0.65,topk: 10,topp: 0.9,beam_delay: 30,beam_block_list_filename: None,temperature: 1.0,compute_tokenized_bleu: False,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,max_lr_steps: -1,invsqrt_lr_decay_gamma: -1,parlai_home: /usr/local/lib/python3.7/dist-packages\u001b[0m\n",
            "15:47:37 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
            "--show-advanced-args False --task internal:new_reddit:presorted --datatype train:stream --numthreads 1 --multitask-weights 1 --batchsize 48 --num-epochs 5.0 --validation-every-n-secs 1800.0 --save-every-n-secs -1 --validation-every-n-epochs -1 --validation-max-exs 9920 --short-final-eval True --validation-patience 0 --dict-build-first True --numworkers 4 --pytorch-preprocess False --pytorch-teacher-batch-sort False --batch-sort-cache-type pop --batch-length-range 5 --shuffle False --batch-sort-field text --pytorch-context-length -1 --pytorch-include-labels True --log-every-n-secs 30.0 --distributed-world-size 64 --port 61337 --beam-size 8 --beam-min-n-best 3 --beam-min-length 10 --skip-generation False --inference beam --optimizer fused_adam --learningrate 0.0005 --gradient-clip 10.0 --adam-eps 1e-06 --betas 0.9,0.98 --weight-decay 0.01 --lr-scheduler invsqrt --warmup-updates 20000 --gpu 0 --beam-block-ngram 3 --beam-context-block-ngram 3\u001b[0m\n",
            "15:47:37 | Using CUDA\n",
            "15:47:37 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model.dict\n",
            "15:47:37 | num words = 54944\n",
            "15:47:39 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "15:47:39 | Loading existing model params from /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model\n",
            "15:48:13 | \u001b[33mNot loading optim state since optim class changed.\u001b[0m\n",
            "15:48:13 | Opt:\n",
            "15:48:13 |     activation: gelu\n",
            "15:48:13 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "15:48:13 |     adam_eps: 1e-08\n",
            "15:48:13 |     add_p1_after_newln: False\n",
            "15:48:13 |     aggregate_micro: False\n",
            "15:48:13 |     allow_missing_init_opts: False\n",
            "15:48:13 |     attention_dropout: 0.0\n",
            "15:48:13 |     batchsize: 16\n",
            "15:48:13 |     beam_block_full_context: True\n",
            "15:48:13 |     beam_block_list_filename: None\n",
            "15:48:13 |     beam_block_ngram: -1\n",
            "15:48:13 |     beam_context_block_ngram: -1\n",
            "15:48:13 |     beam_delay: 30\n",
            "15:48:13 |     beam_length_penalty: 0.65\n",
            "15:48:13 |     beam_min_length: 1\n",
            "15:48:13 |     beam_size: 1\n",
            "15:48:13 |     betas: '(0.9, 0.999)'\n",
            "15:48:13 |     bpe_add_prefix_space: None\n",
            "15:48:13 |     bpe_debug: False\n",
            "15:48:13 |     bpe_dropout: None\n",
            "15:48:13 |     bpe_merge: None\n",
            "15:48:13 |     bpe_vocab: None\n",
            "15:48:13 |     compute_tokenized_bleu: False\n",
            "15:48:13 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "15:48:13 |     datatype: train\n",
            "15:48:13 |     delimiter: '\\n'\n",
            "15:48:13 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "15:48:13 |     dict_endtoken: __end__\n",
            "15:48:13 |     dict_file: /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model.dict\n",
            "15:48:13 |     dict_include_test: False\n",
            "15:48:13 |     dict_include_valid: False\n",
            "15:48:13 |     dict_initpath: None\n",
            "15:48:13 |     dict_language: english\n",
            "15:48:13 |     dict_loaded: True\n",
            "15:48:13 |     dict_lower: True\n",
            "15:48:13 |     dict_max_ngram_size: -1\n",
            "15:48:13 |     dict_maxexs: -1\n",
            "15:48:13 |     dict_maxtokens: -1\n",
            "15:48:13 |     dict_minfreq: 0\n",
            "15:48:13 |     dict_nulltoken: __null__\n",
            "15:48:13 |     dict_starttoken: __start__\n",
            "15:48:13 |     dict_textfields: text,labels\n",
            "15:48:13 |     dict_tokenizer: bpe\n",
            "15:48:13 |     dict_unktoken: __unk__\n",
            "15:48:13 |     display_examples: False\n",
            "15:48:13 |     download_path: None\n",
            "15:48:13 |     dropout: 0.1\n",
            "15:48:13 |     dynamic_batching: full\n",
            "15:48:13 |     embedding_projection: random\n",
            "15:48:13 |     embedding_size: 512\n",
            "15:48:13 |     embedding_type: random\n",
            "15:48:13 |     embeddings_scale: True\n",
            "15:48:13 |     eval_batchsize: None\n",
            "15:48:13 |     eval_dynamic_batching: None\n",
            "15:48:13 |     evaltask: None\n",
            "15:48:13 |     ffn_size: 2048\n",
            "15:48:13 |     force_fp16_tokens: False\n",
            "15:48:13 |     fp16: True\n",
            "15:48:13 |     fp16_impl: safe\n",
            "15:48:13 |     gpu: -1\n",
            "15:48:13 |     gradient_clip: 0.1\n",
            "15:48:13 |     hide_labels: False\n",
            "15:48:13 |     history_add_global_end_token: None\n",
            "15:48:13 |     history_reversed: False\n",
            "15:48:13 |     history_size: -1\n",
            "15:48:13 |     image_cropsize: 224\n",
            "15:48:13 |     image_mode: raw\n",
            "15:48:13 |     image_size: 256\n",
            "15:48:13 |     inference: greedy\n",
            "15:48:13 |     init_model: /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model\n",
            "15:48:13 |     init_opt: None\n",
            "15:48:13 |     interactive_mode: False\n",
            "15:48:13 |     invsqrt_lr_decay_gamma: -1\n",
            "15:48:13 |     jsonfile_datapath: /content/drive/MyDrive/chatbot_data/data\n",
            "15:48:13 |     jsonfile_datatype_extension: True\n",
            "15:48:13 |     label_truncate: 128\n",
            "15:48:13 |     label_turns: both\n",
            "15:48:13 |     learn_positional_embeddings: True\n",
            "15:48:13 |     learningrate: 1e-06\n",
            "15:48:13 |     load_from_checkpoint: True\n",
            "15:48:13 |     log_every_n_secs: 10\n",
            "15:48:13 |     loglevel: info\n",
            "15:48:13 |     lr_scheduler: reduceonplateau\n",
            "15:48:13 |     lr_scheduler_decay: 0.5\n",
            "15:48:13 |     lr_scheduler_patience: 3\n",
            "15:48:13 |     max_lr_steps: -1\n",
            "15:48:13 |     max_train_time: -1\n",
            "15:48:13 |     metrics: default\n",
            "15:48:13 |     model: transformer/generator\n",
            "15:48:13 |     model_file: /content/drive/MyDrive/chatbot_model/model2\n",
            "15:48:13 |     model_parallel: False\n",
            "15:48:13 |     momentum: 0\n",
            "15:48:13 |     multitask_weights: '(1.0, 3.0, 3.0, 3.0)'\n",
            "15:48:13 |     mutators: None\n",
            "15:48:13 |     n_decoder_layers: -1\n",
            "15:48:13 |     n_encoder_layers: -1\n",
            "15:48:13 |     n_heads: 16\n",
            "15:48:13 |     n_layers: 8\n",
            "15:48:13 |     n_positions: 512\n",
            "15:48:13 |     n_segments: 0\n",
            "15:48:13 |     nesterov: True\n",
            "15:48:13 |     no_cuda: False\n",
            "15:48:13 |     num_epochs: -1\n",
            "15:48:13 |     nus: (0.7,)\n",
            "15:48:13 |     optimizer: adamax\n",
            "15:48:13 |     output_scaling: 1.0\n",
            "15:48:13 |     override: \"{'task': 'jsonfile', 'jsonfile_datapath': '/content/drive/MyDrive/chatbot_data/data', 'jsonfile_datatype_extension': True, 'model_file': '/content/drive/MyDrive/chatbot_model/model2', 'dynamic_batching': 'full', 'label_turns': 'both', 'model': 'transformer/generator', 'multitask_weights': (1.0, 3.0, 3.0, 3.0), 'init_model': 'zoo:tutorial_transformer_generator/model', 'dict_file': '/usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model.dict', 'embedding_size': 512, 'n_layers': 8, 'ffn_size': 2048, 'dropout': 0.1, 'n_heads': 16, 'learn_positional_embeddings': True, 'n_positions': 512, 'variant': 'xlm', 'activation': 'gelu', 'skip_generation': True, 'fp16': True, 'text_truncate': 512, 'label_truncate': 128, 'dict_tokenizer': 'bpe', 'dict_lower': True, 'learningrate': 1e-06, 'optimizer': 'adamax', 'lr_scheduler': 'reduceonplateau', 'gradient_clip': 0.1, 'validation_every_n_epochs': 0.25, 'betas': (0.9, 0.999), 'update_freq': 1, 'attention_dropout': 0.0, 'relu_dropout': 0.0, 'validation_patience': 15, 'save_every_n_secs': 60.0, 'validation_max_exs': 20000, 'batchsize': 16, 'validation_metric': 'ppl', 'validation_metric_mode': 'min', 'save_after_valid': True}\"\n",
            "15:48:13 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "15:48:13 |     person_tokens: False\n",
            "15:48:13 |     rank_candidates: False\n",
            "15:48:13 |     relu_dropout: 0.0\n",
            "15:48:13 |     save_after_valid: True\n",
            "15:48:13 |     save_every_n_secs: 60.0\n",
            "15:48:13 |     share_word_embeddings: True\n",
            "15:48:13 |     short_final_eval: False\n",
            "15:48:13 |     skip_generation: True\n",
            "15:48:13 |     special_tok_lst: None\n",
            "15:48:13 |     split_lines: False\n",
            "15:48:13 |     starttime: Mar05_15-47\n",
            "15:48:13 |     task: jsonfile\n",
            "15:48:13 |     temperature: 1.0\n",
            "15:48:13 |     tensorboard_log: False\n",
            "15:48:13 |     tensorboard_logdir: None\n",
            "15:48:13 |     text_truncate: 512\n",
            "15:48:13 |     topk: 10\n",
            "15:48:13 |     topp: 0.9\n",
            "15:48:13 |     truncate: -1\n",
            "15:48:13 |     update_freq: 1\n",
            "15:48:13 |     use_reply: label\n",
            "15:48:13 |     validation_cutoff: 1.0\n",
            "15:48:14 |     validation_every_n_epochs: 0.25\n",
            "15:48:14 |     validation_every_n_secs: -1\n",
            "15:48:14 |     validation_max_exs: 20000\n",
            "15:48:14 |     validation_metric: ppl\n",
            "15:48:14 |     validation_metric_mode: min\n",
            "15:48:14 |     validation_patience: 15\n",
            "15:48:14 |     validation_share_agent: False\n",
            "15:48:14 |     variant: xlm\n",
            "15:48:14 |     verbose: False\n",
            "15:48:14 |     wandb_log: False\n",
            "15:48:14 |     wandb_name: None\n",
            "15:48:14 |     wandb_project: None\n",
            "15:48:14 |     warmup_rate: 0.0001\n",
            "15:48:14 |     warmup_updates: -1\n",
            "15:48:14 |     weight_decay: None\n",
            "15:48:14 | creating task(s): jsonfile\n",
            "15:48:14 | [loading data from json file into task:/content/drive/MyDrive/chatbot_data/data_train.jsonl]\n",
            "15:48:17 | \u001b[31mMetadata does not exist. Please double check your datapath.\u001b[0m\n",
            "15:48:21 | training...\n",
            "15:48:31 | time:10s total_exs:3488 epochs:0.00\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  4504  5601 433.7 3488             16384    inf    .6449 4.681 1e-06  1468  1825 107.9      .2808   \n",
            "    total_train_updates  tpb  tps   ups  \n",
            "                     10 5972 7426 1.244\n",
            "\n",
            "15:48:41 | time:20s total_exs:6796 epochs:0.01\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  6267 10620 329.7 3308             16384  11.39    .6449  4.57 1e-06 886.9  1503 96.57      .3011   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     27 7154 12123 1.695\n",
            "\n",
            "15:48:52 | time:31s total_exs:9196 epochs:0.01\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  7329 13302 229.3 2400             16384   11.1    .5886 4.406 1e-06 582.9  1058 81.93      .3144   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     46 7912 14360 1.815\n",
            "\n",
            "15:49:02 | time:41s total_exs:11468 epochs:0.02\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  7972 15039 225.6 2272             16384  11.05    .5013 4.354 1e-06 527.5   995 77.81      .3370   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     65 8500 16034 1.887\n",
            "\n",
            "15:49:12 | time:51s total_exs:13404 epochs:0.02\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps  ppl  token_acc  \\\n",
            "       1  7872 15122 185.9 1936             16384  10.97    .5393 4.313 1e-06 436.2   838 74.7      .3328   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     85 8308 15960 1.921\n",
            "\n",
            "15:49:21 | saving model checkpoint: /content/drive/MyDrive/chatbot_model/model2.checkpoint\n",
            "15:49:21 | Saving dictionary to /content/drive/MyDrive/chatbot_model/model2.checkpoint.dict\n",
            "15:49:26 | time:65s total_exs:14932 epochs:0.02\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  8275 11141 114.3 1528             16384  11.26    .4549 4.182 1e-06 358.9 483.3 65.52      .3499   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                    103 8634 11624 1.346\n",
            "\n",
            "15:49:36 | time:75s total_exs:16528 epochs:0.02\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  8269 15858   153 1596             16384  11.07    .4816 4.235 1e-06 373.2 715.8 69.05      .3440   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                    123 8642 16574 1.918\n",
            "\n",
            "15:49:46 | time:86s total_exs:17908 epochs:0.02\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  8096 15063 135.1 1380             16384   11.1    .4698 4.345 1e-06 365.6 680.3 77.11      .3220   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                    142 8462 15743 1.861\n",
            "\n",
            "15:49:57 | time:96s total_exs:19188 epochs:0.03\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  8749 17005 124.4 1280             16384  12.11    .4549 4.248 1e-06   307 596.7 69.98      .3313   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                    162 9056 17602 1.944\n",
            "\n",
            "15:50:07 | time:106s total_exs:20448 epochs:0.03\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps  ppl  token_acc  \\\n",
            "       1  8317 15464 123.3 1260             16384  12.23    .5225 4.134 1e-06 298.7 555.4 62.4      .3441   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                    181 8616 16019 1.859\n",
            "\n",
            "15:50:17 | time:117s total_exs:21800 epochs:0.03\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  8137 15685 130.3 1352             16384   11.5    .4413 4.207 1e-06 290.7 560.3 67.13      .3366   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                    201 8428 16245 1.928\n",
            "\n",
            "15:50:26 | saving model checkpoint: /content/drive/MyDrive/chatbot_model/model2.checkpoint\n",
            "15:50:30 | time:129s total_exs:22744 epochs:0.03\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps  ppl  token_acc  \\\n",
            "       1  8639 11369 73.08  944             16384  12.17    .4654 4.206 1e-06 245.4   323 67.1      .3408   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                    218 8884 11692 1.316\n",
            "\n",
            "15:50:41 | time:140s total_exs:23852 epochs:0.03\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  8460 16392 107.3 1108             16384  12.68    .4521 4.304 1e-06 291.1 563.9 73.98      .3182   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                    238 8751 16956 1.938\n",
            "\n",
            "15:50:51 | time:150s total_exs:24900 epochs:0.03\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  8682 15811 100.4 1048             16384   12.3    .4950 4.165 1e-06 262.4 477.9 64.39      .3410   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                    257 8944 16289 1.821\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}